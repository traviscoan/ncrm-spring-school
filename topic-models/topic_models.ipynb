{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic models\n",
    "\n",
    "We will use the `gensim` library to estimate topic models in Python. You will need to install the library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After installing, we can load the necessary functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/Users/tcoan/git_repos/ncrm-spring-school')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "# We will need to following packages to read/write data\n",
    "import pickle\n",
    "import csv\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to find some text data to use and get it in a format that `gensim` likes. We will pull in some data on the Heartland Institute (i.e., a climate change skeptic think tank in the US):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/heartland.pkl', 'rb') as pfile:\n",
    "    heartland = pickle.load(pfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the first row to get a feel for the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heartland[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many documents does `heartland` include:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(heartland)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the \"text_postprocessed\" field in our analysis. This field (or variable if you are a social scientist) takes the raw \"text\" and 1) converts to lowercase, 2) removes punctuation, and 3) removes stopwords. That's it! Note that a number of recent studies suggest that it is better to do as little pre-processing as possible when fitting topic models -- i.e., it is better to \"post\" process, rather than \"pre\" process. See Schofield et al. <a href = \"http://www.cs.cornell.edu/~xanda/winlp2017.pdf\">\"Understanding Text Pre-Processing for Latent Dirichlet Allocation\"</a>.\n",
    "\n",
    "Next, we tokenize of text for `gensim` and create a gensim `Dictionary`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for gensim\n",
    "documents = [row['text_postprocessed'] for row in heartland]\n",
    "texts = [doc.split(' ') for doc in documents]\n",
    "\n",
    "# Make gensim corpus object\n",
    "dictionary = corpora.Dictionary(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dictionary just maps our tokens (words) from strings to integers. For instance, let's view the mapping for the word \"alarmist\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look up the integer ID if we have a token key\n",
    "print(dictionary.token2id['alarmist'])\n",
    "\n",
    "# And vice-a-versa\n",
    "print(dictionary[10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to \"vectorize\" our data based on the dictionary mapping created above. Here, we vectorize using the `doc2bow()` method (i.e., document to \"bag of words\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gensim corpus object\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This `corpus` object holds the same information as the \"document-term matrix\" that we created in `sklearn`, but it is stored in a different (efficient) format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(corpus[1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we are ready to estimate our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate!\n",
    "k = 30\n",
    "lda = LdaModel(corpus, num_topics=k, iterations=100, alpha = 'auto',\n",
    "               id2word=dictionary, random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it! We can pull out the topic distribution ($\\theta$) and the word distribution ($\\phi$) as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documents on the rows and topic proportions on the columns\n",
    "theta = lda.get_document_topics(corpus, minimum_probability = 0)\n",
    "\n",
    "# Topics on the rows and words on the columns\n",
    "phi = lda.get_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'theta has {len(theta)} rows and {len(theta[0])}')\n",
    "print(f'phi has {len(phi)} rows and {len(phi[0])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working with these matrices directly is a bit of a pain and ``gensim`` offers a number of methods to make examining your results easier. We'll look at some of those below, in the context of topic interpretation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic interpretation\n",
    "\n",
    "We typically start our analysis of our topic model results by examining the topic **keywords**, examining the **assignment frequencies** of our topics, and analyzing the **semantic coherence** of our topics. We will extract the relevant information from our fitted `gensim` model to achieve each of these objectives.\n",
    "\n",
    "## Keywords\n",
    "\n",
    "We start the process of topic interpretation and validation by examining the topic **keywords**. These \"keywords\" are probable tokens under the model -- i.e., the tokens most often assigned to a particular topic. We can by using the `show_topic()` or `show_topics()` method for LDA objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lda.show_topic(10, topn = 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = lda.show_topics(num_topics=30, num_words = 5)\n",
    "for key in keys:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm not crazy about gensim's default display of keywords. Instead, I like to use to extract and view the topics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# You will need to install prettytable to run this! E.g.,\n",
    "# pip install prettytable\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "def view_keywords(model, num_topics, num_words = 10, prettyprint = True):\n",
    "    # Return keywords from gensim\n",
    "    keywords = model.show_topics(num_topics = num_topics, \n",
    "                               num_words = num_words, \n",
    "                               formatted=False)\n",
    "\n",
    "    # Reformat keyword results for easy viewing\n",
    "    output = []\n",
    "    for row in keywords:\n",
    "        tokens = ' '.join([token[0] for token in row[1]])\n",
    "        output.append([row[0], tokens])\n",
    "    \n",
    "    # Print a nicely formatted table\n",
    "    if prettyprint:\n",
    "        tbl = PrettyTable()\n",
    "                \n",
    "        # Column labels\n",
    "        tbl.field_names = [\"Topic ID\", \"Keywords\"]\n",
    "        \n",
    "        # Populate table\n",
    "        for row in output:\n",
    "            tbl.add_row(row)\n",
    "        \n",
    "        # Output formatted table\n",
    "        tbl.align = \"l\"\n",
    "        print(tbl)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use this function to view keywords in a format that doesn't hurt the eyes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = view_keywords(lda, lda.num_topics, num_words = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do we decide what a topic is about?\n",
    "\n",
    "We read! That is, we often look at a handful of the most probable documents for each topic. Here's a function that does just that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_documents(content, topic_id, theta, n = 10):\n",
    "    ''' Takes a topic id and the full document-topic \n",
    "        matrix (theta) and returns the indices for the \n",
    "        top n documents. '''\n",
    "    \n",
    "    x = theta[topic_id,:].todense()\n",
    "    idx = np.argpartition(x[0,:], -n)[0,-n:]\n",
    "    \n",
    "    # Get sorted IDs\n",
    "    idx_sorted = idx[0, np.argsort(-x[0,idx])].tolist()[0]\n",
    "    \n",
    "    # Find and return the top documents\n",
    "    return [row for i,row in enumerate(content) if i in set(idx_sorted)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Extracting the full theta matrix. This can be slow!')\n",
    "theta = gensim.matutils.corpus2csc(lda[corpus])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use our function to pull the top `n` most probable documents for a given topic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(top_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_docs = top_documents(heartland, 1, theta)\n",
    "print(top_docs[1]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_docs[2]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic assignment frequency\n",
    "\n",
    "Next, I like to extract on overall measure of the **importance** of a topic to a corpus. Here, we can define a function to extract the topic assignment frequencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to return the topic frequency\n",
    "def topic_frequency(model, corpus, proportion = True, LOG_EVERY_N = 1000):\n",
    "    ''' Takes a gensim model object and a corpus object\n",
    "        and returns the number of words assigned to each\n",
    "        topic. '''\n",
    "    \n",
    "    # Extract topic distributions\n",
    "    theta = model.get_document_topics(corpus, minimum_probability = 0)\n",
    "    \n",
    "    # Extract number of words in each document\n",
    "    n = [sum([row[1] for row in doc]) for doc in corpus]\n",
    "    \n",
    "    # Get topic assignments\n",
    "    print('Extracting topic assignments for each token...')\n",
    "    \n",
    "    counts = []\n",
    "    for i,row in enumerate(theta):\n",
    "        # Extract topic assignemnt counts\n",
    "        counts.append([round(el[1]*n[i]) for el in row])\n",
    "        \n",
    "        # Log progress\n",
    "        if (i % LOG_EVERY_N) == 0:\n",
    "            print('Finished processing %s documents' % i)\n",
    "            \n",
    "    # Convert to a numpy array\n",
    "    counts_matrix = np.array(counts)\n",
    "    \n",
    "    # Sum down topics to get assignment totals\n",
    "    assignments = np.sum(counts_matrix, axis = 0)\n",
    "    \n",
    "    if proportion:\n",
    "        res = assignments/np.sum(assignments)\n",
    "    else:\n",
    "        res = assignments\n",
    "    \n",
    "    return res.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then get the assignment proportions by simply calling the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract topic assignments\n",
    "assignments = topic_frequency(lda, corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can print the assignment proportions out to get a sense of topic prevelance in our corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in enumerate(assignments):\n",
    "    print('Topic %s = %s' % (i, round(row, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic \"quality\"\n",
    "\n",
    "How good our our topics? This is a tough question and there are many ways to answer it. Two common measures for examining topic quality are 1) **semantic coherence** and 2) topic **exclusivity**. Let's look at each in turn.\n",
    "\n",
    "### Semantic coherence\n",
    "\n",
    "One useful measure of topic quality is so-called semantic (or topic) coherence. It is easy to implement a wide-range of coherence measures in `gensim`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = [row[1].split(' ') for row in keywords]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull out and tokenize the topic keywords\n",
    "topics = [row[1].split(' ') for row in keywords]\n",
    "\n",
    "# Estimate coherence. The 'u_mass' and 'c_v'\n",
    "# methods are good to try.\n",
    "co = CoherenceModel(topics=topics,\n",
    "                    texts=texts,\n",
    "                    dictionary=dictionary,\n",
    "                    coherence='c_v')\n",
    "\n",
    "# Extract semantic coherence for each topic\n",
    "semantic = co.get_coherence_per_topic()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can view the semantic coherence associated with each topic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in enumerate(semantic):\n",
    "    print('Topic %s = %s' % (i, row))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can average over the topics to calculate the semantic coherence of our overall model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Model coherence = %s' % np.mean(semantic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exclusivity\n",
    "\n",
    "As you estimate topic models in your own research, you will notice that some topics include very similar words. For instance, for our Heartland Institute topic model above, there are quite of few \"energy\" topics. This is often a sign that we've estimated a model with too many topics (more on this below!).\n",
    "\n",
    "One way to calculate **topic exclusivity** is to start with the \"word\" exclusivity for each topic keyword:\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{P(w_{i}|k=t)}{P(w_{i})}\n",
    "\\end{equation}\n",
    "\n",
    "That is, we calculate the probability of each word ($w_{i}$) given a particular topic ($t$), divided by the overall (or marginal) probability of $w_{i}$. Here's a function that takes care of this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note you could get a DeprecationWarning here, depending on your\n",
    "# version of IPython. Either ignore it or upgrade IPython:\n",
    "# pip install --upgrade ipykernel\n",
    "\n",
    "def exclusivity(model, dictionary, num_words = 10):\n",
    "    # Return topic keywords\n",
    "    topics = model.show_topics(model.num_topics, \n",
    "                               formatted=False,\n",
    "                               num_words=num_words)\n",
    "    \n",
    "    # Get word distribution (phi)\n",
    "    topic_word_matrix = model.get_topics()\n",
    "    \n",
    "    # Calculate the marginal probability of the word\n",
    "    word_prob = np.sum(topic_word_matrix, axis=0)\n",
    "    \n",
    "    # Return exclusivity for each topic-word combination\n",
    "    ex_matrix = topic_word_matrix / word_prob[None,:]\n",
    "    \n",
    "    # Parse topic keywords  \n",
    "    keys_ = [[(k[0]) for k in topic[1]] \n",
    "             for topic in topics]\n",
    "    \n",
    "    # Return mean word exclusivity as a measure of \"topic\"\n",
    "    # exclusvity\n",
    "    return [np.mean([ex_matrix[topic[0], dictionary.token2id[k]] \n",
    "                     for k in keys_[topic[0]]])\n",
    "            for topic in topics]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = exclusivity(lda, dictionary)\n",
    "\n",
    "# Print exclusivity for each topic\n",
    "for i, row in enumerate(ex):\n",
    "    print(\"Topic %s = %s\" % (i, row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing the results to disk\n",
    "\n",
    "While you could view coherence in the Python console, I typically prefer to write everything out to a CSV file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_to_write = []\n",
    "for i,topic in enumerate(topics):\n",
    "    topics_to_write.append({'topic_id': i, \n",
    "                             'topic_prop': assignments[i], \n",
    "                             'coherence': semantic[i], \n",
    "                             'exlusivity': ex[i], \n",
    "                             'keywords': ' '.join(topic)})\n",
    "df_topics = pd.DataFrame(topics_to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_topics.sort_values('coherence', ascending=False)\n",
    "df_topics.to_csv('/Users/tcoan/git_repos/notebooks/TopicModels/topics_heartland.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic visualization\n",
    "\n",
    "One useful way to view topic models generated by `gensim` is using the `PyLDAvis` library. To install from jupyter, use the standard:\n",
    "\n",
    "`!pip install pyldavis`\n",
    "\n",
    "And then to run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim as gensimvis\n",
    "import pyLDAvis\n",
    "\n",
    "vis_data = gensimvis.prepare(lda, corpus, dictionary)\n",
    "pyLDAvis.display(vis_data)\n",
    "\n",
    "# You save an HTML file with the same information, using\n",
    "# pyLDAvis.save_html(vis_data,'vis.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting the topic number, *k*\n",
    "\n",
    "As we discussed in class, there's not a great \"automated\" way to select the \"optimal\" topic number and I would argue that the whole notion of an \"optimal\" solution is misguided. There are, however, better and worse solutions. My preferred way to choose the topic number, *k*, is to combine a measure of **semantic coherence** with a qualitative inspection of a particular solution. I ask myself the following basic question: *what do we gain and what do we lose by increasing the overall number of topics*?\n",
    "\n",
    "Here's an example of a loop that calculates and stores the relevant information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parameters for the loop\n",
    "start_k = 5\n",
    "end_k = 30\n",
    "step_k = 5\n",
    "cv_method = 'u_mass'\n",
    "top_n = 10\n",
    "iterations = 50\n",
    "\n",
    "results = []\n",
    "for k in range(start_k, end_k, step_k):\n",
    "    print(\"Fit k = %s\" % k)\n",
    "    model = LdaModel(corpus, num_topics=k, iterations=iterations,\n",
    "               alpha = 'auto', id2word=dictionary, \n",
    "               random_state=12345)\n",
    "    \n",
    "    cm = CoherenceModel(model=model, \n",
    "                    texts=texts, \n",
    "                    dictionary=dictionary, \n",
    "                    coherence=cv_method,\n",
    "                    topn=top_n)\n",
    "    \n",
    "    coherence = cm.get_coherence()\n",
    "    print(\"Coherence = %s\" % coherence)\n",
    "    \n",
    "    results.append({'model': model,\n",
    "                    'coherence': [k, coherence]})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So based on the `u_mass` estimator, the \"optimal\" solution is somewhere near $k = 10$. Let's take a look at a view of these solutions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1\n",
    "keywords = view_keywords(results[idx]['model'], results[idx]['model'].num_topics, num_words = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting topic model data\n",
    "\n",
    "Once you have a model that you are happy with, you can extact the <b>document-topic matrix</b> for future use. For instance, consider the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the document-topic matrix \"theta\")\n",
    "theta = lda.get_document_topics(corpus, minimum_probability = 0)\n",
    "\n",
    "# Parse \"theta\" and store topic proportions\n",
    "proportions = []\n",
    "for row in theta:\n",
    "    proportions.append([el[1] for el in row])\n",
    "\n",
    "print(proportions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(proportions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will provide a Python list of the relevant topic probabilities in the same order as the orginal `heartland` corpus. We can append these probabilities to our dataset and write to disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a little function to \"flatten\" a list\n",
    "def flatten(list_of_lists):\n",
    "    return [item for sublist in list_of_lists for item in sublist]\n",
    "\n",
    "# Prepare file to write\n",
    "data_to_write = []\n",
    "for i,row in enumerate(proportions):\n",
    "    meta = [heartland[i]['docid'], heartland[i]['date'], heartland[i]['title']]\n",
    "    data_to_write.append(flatten([meta, row]))\n",
    "\n",
    "# Write a CSV file\n",
    "with open('heartland_data.csv', 'w') as csvfile:\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    csvwriter.writerows(data_to_write)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting topic time series\n",
    "\n",
    "Once we've extracted our data, what can we do with it? Often we are interested the dynamics of topic prevalence over time. As an example, say that we use the 15 topic solution and want to plot the average topic proportion on climate science over time. And to make things simple, assume that we want to plot the topic proportion at the yearly level. The first thing that we need to do is format our \"date\" variable and pull out the relevant year:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import a module to deal with datetime\n",
    "from datetime import datetime\n",
    "\n",
    "# Let's strip the very first date to see how this works\n",
    "datetime.strptime(data_to_write[0][1], '%m/%d/%Y').year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_write[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just need to loop over our data and extact the year:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in data_to_write:\n",
    "    date = datetime.strptime(row[1], '%d/%m/%Y')\n",
    "    row.append(date.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_to_write[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(data_to_write)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's give our data frame better variable names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list of column names\n",
    "cnames = flatten([['docid', 'date', 'title'], ['topic' + str(i) \n",
    "                                               for i in range(30)], ['year']])\n",
    "\n",
    "# Here's what the list looks like\n",
    "print(cnames)\n",
    "\n",
    "# Rename columns\n",
    "df.columns = cnames\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we aggregate our topics by year using the average:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data groups by year\n",
    "grouped = df.groupby('year')\n",
    "\n",
    "# Aggregate groups based on the mean\n",
    "df_ts = grouped.aggregate(np.mean)\n",
    "\n",
    "# Let's take a look\n",
    "df_ts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can plot the time series. We need to import plotting functionality from `matplotlib` and format in a pandas `Series`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Format the pandas variable in a Series\n",
    "ts = pd.Series(df_ts['topic1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ts.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extensions to the LDA\n",
    "\n",
    "We've discussed that one of the reasons that the LDA has been so influential is the ease with which it can be extended. Let's take a look a couple of extensions that could be very useful in your research. While there are a number of different implementations in Python available, we will be using the `tomotopy` library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tomotopy # install to use!\n",
    "import tomotopy as tp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seeded LDA\n",
    "\n",
    "The \"seeded\" or \"guided\" LDA offers a semi-supervised approach to \"nudge\" topics to a particular concept or theme by using a set of keywords. The way we do this in practice is by setting the priors on words in a way that pushes a word onto a topic. Let's start with the basic LDA in `tomotopy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the LDA model\n",
    "model = tp.LDAModel(k=20)\n",
    "\n",
    "# Add documents to the model\n",
    "for text in texts:\n",
    "    model.add_doc(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model for 100 iterations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(model.k):\n",
    "    print('Top 10 words of topic #{}'.format(k))\n",
    "    print(model.get_topic_words(k, top_n=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(model.k):\n",
    "    print(f'Topic #{k}: {\" \".join([keyword[0] for keyword in model.get_topic_words(k, top_n=10)])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, so that's the standard LDA -- how do we get the seeded version? We do so by setting the word priors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to re-instantiate the LDA model\n",
    "model = tp.LDAModel(k=20)\n",
    "\n",
    "# Add documents to the model\n",
    "for text in texts:\n",
    "    model.add_doc(text)\n",
    "\n",
    "model.set_word_prior('kyoto', [1.0 if k == 0 else 0.1 for k in range(20)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(100)\n",
    "for k in range(model.k):\n",
    "    print(f'Topic #{k}: {\" \".join([keyword[0] for keyword in model.get_topic_words(k, top_n=10)])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also easily add additional \"seeds\" to our model using something like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to re-instantiate the LDA model\n",
    "model = tp.LDAModel(k=20)\n",
    "\n",
    "# Add documents to the model\n",
    "for text in texts:\n",
    "    model.add_doc(text)\n",
    "\n",
    "# Set up seed words\n",
    "keyword_seeds = [['kyoto', 'agreement', 'copenhagen'], \n",
    "                 ['energy', 'fossil', 'fuel'], \n",
    "                 ['gore', 'inconvenient']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,seeds in enumerate(keyword_seeds):\n",
    "    for word in seeds:\n",
    "        model.set_word_prior(word, [1.0 if k == i else 0.1 for k in range(20)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(100)\n",
    "for k in range(model.k):\n",
    "    print(f'Topic #{k}: {\" \".join([keyword[0] for keyword in model.get_topic_words(k, top_n=10)])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the <a href=\"https://bab2min.github.io/tomotopy/v0.12.2/en/#tomotopy\">tomotopy</a> hompage for more on the models they support, which include:\n",
    "\n",
    "* Latent Dirichlet Allocation (LDAModel)\n",
    "* Labeled LDA (LLDAModel)\n",
    "* Partially Labeled LDA (PLDAModel)\n",
    "* Supervised LDA (SLDAModel)\n",
    "* Dirichlet Multinomial Regression (DMRModel)\n",
    "* Generalized Dirichlet Multinomial Regression (GDMRModel)\n",
    "* Hierarchical Dirichlet Process (HDPModel)\n",
    "* Hierarchical LDA (HLDAModel)\n",
    "* Multi Grain LDA (MGLDAModel)\n",
    "* Pachinko Allocation (PAModel)\n",
    "* Hierarchical PA (HPAModel)\n",
    "* Correlated Topic Model (CTModel)\n",
    "* Dynamic Topic Model (DTModel)\n",
    "* Pseudo-document based Topic Model (PTModel).\n",
    "\n",
    "And for examples of the applicaiton of several of these extentions in my publications, see:\n",
    "\n",
    "* Seeded LDA: https://www.mdpi.com/2225-1154/7/3/45/htm\n",
    "* Labeled LDA: https://www.cambridge.org/core/journals/politics-and-religion/article/political-speech-in-religious-sermons/53583EA3BD5F4223B5E31AA279698563"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "LDA-based models are no longer the only game in town and there are a number of exciting extensions that have their roots in language models. The `BERTopic` library ('https://github.com/MaartenGr/BERTopic) is the most well-developed version of this topic modelling strategy and can be used for:\n",
    "\n",
    "* Guided topic modeling\n",
    "* Supervised topic modeling\n",
    "* Semi-supervised modeling\n",
    "* Hierarchical modeling\n",
    "* Dynamic topic modeling\n",
    "* Etc., etc.!\n",
    "\n",
    "I highly recommend checking the package out and comparing it to the classic LDA approach."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "0db7a017d97a45ffea759374b98e80b051fa13973580c065a6b8f6e28c7ab80d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
